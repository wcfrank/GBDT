{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To explore the `fit` method of class `GBDT`\n",
    "Firstly, explore the function of binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# open('data/credit.data.csv').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import sample\n",
    "from gbdt.data import DataSet\n",
    "from gbdt.model import GBDT\n",
    "from gbdt.model import BinomialDeviance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = DataSet('data/credit.data.csv')\n",
    "dataset.get_label_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The initial properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_iter = 20\n",
    "sample_rate = 0.8\n",
    "learn_rate = 0.5\n",
    "max_depth = 7\n",
    "loss_type = 'binary-classification'\n",
    "split_points = 0\n",
    "\n",
    "trees = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function: Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = BinomialDeviance(n_classes=dataset.get_label_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "653"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.initialize(f, dataset)\n",
    "len(f.keys())\n",
    "# f: f is a dict, and it has 653 key-value pairs. Keys are integers from 1 to 653, and all the values are set to be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset.get_instances_idset()\n",
    "# train_data is a set, which contains IDs from 1 to 653"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary classification:\n",
    "\n",
    "The residual is $Residual_i = \\frac{2y_i}{1+exp(2y_if_i)} $. Log loss deviance\n",
    "\n",
    "\n",
    "Why loss is as above? Refer to \n",
    "- [Scikit Binomial Deviance Loss Function](https://stats.stackexchange.com/questions/157870/scikit-binomial-deviance-loss-function)\n",
    "- [How to derive bernoulli deviance](https://stats.stackexchange.com/questions/208331/how-to-derive-bernoulli-deviance)\n",
    "- It is called binomial negative log-likelihood loss:\n",
    "https://pdfs.semanticscholar.org/7efc/245d8ad4cbd6489e3dca6688264bf4f83579.pdf\n",
    "- in ESL, it is called __binomial deviance__ or __binomial negative log-likelihood__ P346 \n",
    "- [GBDT模型](https://www.jianshu.com/p/0bc32c8e4ca8)\n",
    "- [GBDT训练分类器时，残差是如何计算的？](https://blog.csdn.net/mmc2015/article/details/52398488)\n",
    "- Friedman's paper: [Greedy Function Approximation: A Gradient Boosting Machine](http://docs.salford-systems.com/GreedyFuncApproxSS.pdf)\n",
    "\n",
    "The negative binomial log-likelihood loss: $L(y, F) = \\log(1+ \\exp(-2yF)),~~~ y\\in\\{-1,1\\}$. There is an coefficient of 2, because here the label is -1 and 1. If the label is 0 and 1, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of initial subset is 653\n",
      "the size of sampled subset is 522 , only 80% of the initial size\n",
      "522\n"
     ]
    }
   ],
   "source": [
    "iter = 1 # for iter in range(1, max_iter+1):\n",
    "subset = train_data\n",
    "print('the size of initial subset is', len(subset))\n",
    "if 0 < sample_rate < 1:\n",
    "    subset = sample(subset, int(len(subset)*sample_rate))\n",
    "    print('the size of sampled subset is', len(subset), ', only 80% of the initial size')\n",
    "residual = loss.compute_residual(dataset, subset, f) # residual is a dict, in which keys are the sampled IDs \n",
    "print(len(residual))\n",
    "\n",
    "leaf_nodes = []\n",
    "targets = residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
