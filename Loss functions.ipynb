{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To explore the `fit` method of class `GBDT`\n",
    "Firstly, explore the function of binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# open('data/credit.data.csv').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import sample\n",
    "from gbdt.data import DataSet\n",
    "from gbdt.model import GBDT\n",
    "from gbdt.model import BinomialDeviance\n",
    "from gbdt.tree import construct_decision_tree, Tree\n",
    "from gbdt.tree import MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = DataSet('data/credit.data.csv')\n",
    "dataset.get_label_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The initial properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_iter = 20\n",
    "sample_rate = 0.8\n",
    "learn_rate = 0.5\n",
    "max_depth = 7\n",
    "loss_type = 'binary-classification'\n",
    "split_points = 0\n",
    "\n",
    "trees = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function: Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = BinomialDeviance(n_classes=dataset.get_label_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "653"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.initialize(f, dataset)\n",
    "len(f.keys())\n",
    "# f: f is a dict, and it has 653 key-value pairs. Keys are integers from 1 to 653, and all the values are set to be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = dataset.get_instances_idset()\n",
    "# train_data is a set, which contains IDs from 1 to 653"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary classification:\n",
    "\n",
    "The residual is $Residual_i = \\frac{2y_i}{1+exp(2y_if_i)} $. (Log loss deviance)\n",
    "\n",
    "\n",
    "Why loss is as above? Refer to \n",
    "- [Scikit Binomial Deviance Loss Function](https://stats.stackexchange.com/questions/157870/scikit-binomial-deviance-loss-function)\n",
    "- [How to derive bernoulli deviance](https://stats.stackexchange.com/questions/208331/how-to-derive-bernoulli-deviance)\n",
    "- It is called binomial negative log-likelihood loss:\n",
    "https://pdfs.semanticscholar.org/7efc/245d8ad4cbd6489e3dca6688264bf4f83579.pdf\n",
    "- in ESLII, it is called __binomial deviance__ or __binomial negative log-likelihood__ P346 \n",
    "- [GBDT模型](https://www.jianshu.com/p/0bc32c8e4ca8)\n",
    "- [GBDT训练分类器时，残差是如何计算的？](https://blog.csdn.net/mmc2015/article/details/52398488)\n",
    "- Friedman's paper: [Greedy Function Approximation: A Gradient Boosting Machine](http://docs.salford-systems.com/GreedyFuncApproxSS.pdf)\n",
    "\n",
    "The negative binomial log-likelihood loss: $L(y, F) = \\log(1+ \\exp(-2yF)),~~~ y\\in\\{-1,1\\}$. \n",
    "\n",
    "There is an coefficient of 2, because here the label is -1 and 1. \n",
    "\n",
    "If the label is 0 and 1, $L(y, F) = \\log(1+ \\exp(-yF)),~~~ y\\in\\{0,1\\}$\n",
    "\n",
    "这两个公式本质上是一样的，只是因为label的不同而不同，相互转化的过程参考ESLII的P346即可。因为这里的label是-1,1，所以我们必须使用前一种损失函数！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of initial subset is 653\n",
      "the size of sampled subset is 522 , only 80% of the initial size\n",
      "522\n"
     ]
    }
   ],
   "source": [
    "iter = 1 # for iter in range(1, max_iter+1):\n",
    "subset = train_data\n",
    "print('the size of initial subset is', len(subset))\n",
    "if 0 < sample_rate < 1:\n",
    "    subset = sample(subset, int(len(subset)*sample_rate))\n",
    "    print('the size of sampled subset is', len(subset), ', only 80% of the initial size')\n",
    "residual = loss.compute_residual(dataset, subset, f) # residual is a dict, in which keys are the sampled IDs \n",
    "print(len(residual))\n",
    "\n",
    "leaf_nodes = []\n",
    "targets = residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tree = construct_decision_tree(dataset, subset, targets, 0, leaf_nodes, max_depth, loss, split_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree.conditionValue\n",
    "# tree.describe()\n",
    "# # tree.leafNode\n",
    "# tree.real_value_feature\n",
    "# tree.split_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now explore what is exactly function `construct_decision_tree` is:\n",
    "\n",
    "`depth =  0`\n",
    "\n",
    "`if depth < max_depth`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A1',\n",
       " 'A2',\n",
       " 'A3',\n",
       " 'A4',\n",
       " 'A5',\n",
       " 'A6',\n",
       " 'A7',\n",
       " 'A8',\n",
       " 'A9',\n",
       " 'A10',\n",
       " 'A11',\n",
       " 'A12',\n",
       " 'A13',\n",
       " 'A14',\n",
       " 'A15')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = dataset.get_attributes()\n",
    "attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse = -1\n",
    "selectedAttibute = None\n",
    "conditionValue = None\n",
    "selectedLeftIdSet = []\n",
    "selectedRightIdSet = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for attribute in attributes:\n",
    "    is_real_type = dataset.is_real_type_field(attribute)\n",
    "    attrValues = dataset.get_distinct_valueset(attribute)\n",
    "    if is_real_type and split_points > 0 and len(attrValues) > split_points: # Here is False, no next line\n",
    "        attrValues = sample(attrValues, split_points)\n",
    "    for attrValue in attrValues:\n",
    "        leftIdSet = []\n",
    "        rightIdSet = []    \n",
    "        for Id in subset:\n",
    "            instance = dataset.get_instance(Id) # a dict\n",
    "            value = instance[attribute]\n",
    "            # 计算量巨大：如果这个attribute有1000种不同取值，subset中有500个Id，则下面的判断条件要运行5*10^5遍\n",
    "            # 枚举此attribute的每个取值，进行节点的分裂，找到loss最小的那个\n",
    "            if (is_real_type and value< attrValue) or (not is_real_type and value == attrValue):\n",
    "                leftIdSet.append(Id)\n",
    "            else:\n",
    "                rightIdSet.append(Id)\n",
    "        leftTargets = [targets[id] for id in leftIdSet] # 梯度\n",
    "        rightTargets = [targets[id] for id in rightIdSet]\n",
    "        sum_mse = MSE(leftTargets)+MSE(rightTargets)\n",
    "#         print(sum_mse)\n",
    "        if mse < 0 or sum_mse < mse:\n",
    "            selectedAttribute = attribute\n",
    "            conditionValue = attrValue\n",
    "            mse = sum_mse\n",
    "            selectedLeftIdSet = leftIdSet\n",
    "            selectedRightIdSet = rightIdSet\n",
    "#     print('Is real type:', is_real_type, '   Attribute values:', attrValues)\n",
    "#     print(mse)\n",
    "#     print(leaf_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = Tree()\n",
    "tree.split_feature = selectedAttribute\n",
    "tree.real_value_feature = dataset.is_real_type_field(selectedAttribute)\n",
    "tree.conditionValue = conditionValue\n",
    "tree.leftTree = construct_decision_tree(dataset, selectedLeftIdSet, targets, 1, leaf_nodes, max_depth, loss)\n",
    "tree.rightTree = construct_decision_tree(dataset, selectedRightIdSet, targets, 1, leaf_nodes, max_depth, loss)\n",
    "# 经过construct_decision_tree这个递归函数之后，Id最后都在leaf_nodes中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the subset Id are all in the leaf nodes eventually\n",
    "listlen = [i.idset for i in leaf_nodes]\n",
    "sum([len(i) for i in listlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.update_f_value(f, tree, leaf_nodes, subset, dataset, learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
